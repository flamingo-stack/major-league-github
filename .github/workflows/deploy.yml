name: Build and Deploy Major League Github üöÄ ü¶©

on:
  push:
    branches: [ main ]
  workflow_dispatch:

env:
  PROJECT_NAME: ${{ secrets.PROJECT_NAME }}
  VERSION: v1.0.${{ github.run_number }}
  ENVIRONMENT: production
  
  # DigitalOcean
  REGISTRY: ${{ secrets.REGISTRY }}
  REGISTRY_NAME: ${{ secrets.REGISTRY_NAME }}
  DIGITALOCEAN_ACCESS_TOKEN: ${{ secrets.DIGITALOCEAN_ACCESS_TOKEN }}

  DOMAIN_NAME: ${{ secrets.DOMAIN_NAME }}
  DOMAIN_SUFFIX: ${{ secrets.DOMAIN_SUFFIX }}

  GH_PAT: ${{ secrets.GH_PAT }}
  GH_API_TOKENS: ${{ secrets.GH_API_TOKENS }}
  
  # Cluster configuration
  CLUSTER_NAME: ${{ secrets.CLUSTER_NAME }}
  CLUSTER_REGION: nyc3
  CLUSTER_SIZE: s-4vcpu-8gb
  CLUSTER_NODE_COUNT: 1
  CLUSTER_VERSION: latest
  
  # Replica counts
  BACKEND_REPLICAS: 1
  FRONTEND_REPLICAS: 1
  
  # Backend resources
  BACKEND_REQUEST_MEMORY: 512Mi
  BACKEND_REQUEST_CPU: 200m
  BACKEND_LIMIT_MEMORY: 1Gi
  BACKEND_LIMIT_CPU: 500m
  
  # Frontend resources
  FRONTEND_REQUEST_MEMORY: 128Mi
  FRONTEND_REQUEST_CPU: 100m
  FRONTEND_LIMIT_MEMORY: 256Mi
  FRONTEND_LIMIT_CPU: 200m
  
  # Java settings
  JAVA_MAX_HEAP: 768m
  JAVA_MIN_HEAP: 512m

jobs:
  build-and-deploy:
    runs-on: ubuntu-22.04
    permissions:
      contents: read
      packages: write
      deployments: write

    steps:
      - name: Verify Required Secrets üîí
        run: |
          missing_secrets=()
          
          if [ -z "${{ secrets.PROJECT_NAME }}" ]; then
            missing_secrets+=("PROJECT_NAME")
          fi
          
          if [ -z "${{ secrets.REGISTRY }}" ]; then
            missing_secrets+=("REGISTRY")
          fi
          
          if [ -z "${{ secrets.REGISTRY_NAME }}" ]; then
            missing_secrets+=("REGISTRY_NAME")
          fi
          
          if [ -z "${{ secrets.DIGITALOCEAN_ACCESS_TOKEN }}" ]; then
            missing_secrets+=("DIGITALOCEAN_ACCESS_TOKEN")
          fi
          
          if [ -z "${{ secrets.DOMAIN_NAME }}" ]; then
            missing_secrets+=("DOMAIN_NAME")
          fi
          
          if [ -z "${{ secrets.DOMAIN_SUFFIX }}" ]; then
            missing_secrets+=("DOMAIN_SUFFIX")
          fi
          
          if [ -z "${{ secrets.GH_PAT }}" ]; then
            missing_secrets+=("GH_PAT")
          fi
          
          if [ -z "${{ secrets.GH_API_TOKENS }}" ]; then
            missing_secrets+=("GH_API_TOKENS")
          fi
          
          if [ -z "${{ secrets.CLUSTER_NAME }}" ]; then
            missing_secrets+=("CLUSTER_NAME")
          fi
          
          if [ ${#missing_secrets[@]} -ne 0 ]; then
            echo "‚ùå Error: Missing required secrets: ${missing_secrets[*]}"
            exit 1
          fi
          
          echo "‚úÖ All required secrets are set"

      - name: Checkout code üì¶
        uses: actions/checkout@v4
        with:
          token: ${{ env.GH_PAT }}

      - name: Install doctl üõ†Ô∏è
        uses: digitalocean/action-doctl@v2
        with:
          token: ${{ env.DIGITALOCEAN_ACCESS_TOKEN }}

      - name: Setup DigitalOcean Infrastructure üèóÔ∏è
        run: |
          echo "ü¶© Validating DigitalOcean credentials..."
          if ! doctl account get > /dev/null 2>&1; then
            echo "‚ùå Error: Invalid DigitalOcean credentials"
            exit 1
          fi
          
          echo "ü¶© Creating DigitalOcean Project..."
          PROJECT_ID=""
          
          # First try to list all projects and find ours
          echo "ü¶© Checking for existing project..."
          if PROJECT_ID=$(doctl projects list --format ID,Name --no-header | grep -i "${PROJECT_NAME}" | awk '{print $1}') && [ ! -z "$PROJECT_ID" ]; then
            echo "‚úÖ Found existing project with ID: ${PROJECT_ID}"
          else
            echo "ü¶© Creating new project: ${PROJECT_NAME}..."
            if PROJECT_ID=$(doctl projects create \
              --name "${PROJECT_NAME}" \
              --purpose "Production" \
              --environment "Production" \
              --description "Major League GitHub Infrastructure" \
              --format ID --no-header); then
              echo "‚úÖ Project created successfully with ID: ${PROJECT_ID}"
            else
              echo "‚ùå Error: Failed to create project"
              exit 1
            fi
          fi
          
          # Double check we have a valid project ID
          if [ -z "$PROJECT_ID" ] || ! doctl projects get "$PROJECT_ID" > /dev/null 2>&1; then
            echo "‚ùå Error: Invalid project ID: ${PROJECT_ID}"
            exit 1
          fi
          
          echo "ü¶© Project ID confirmed: ${PROJECT_ID}"
          
          echo "ü¶© Checking DigitalOcean Registry..."
          if ! doctl registry get > /dev/null 2>&1; then
            echo "ü¶© Creating DigitalOcean Registry..."
            if ! doctl registry create "${REGISTRY_NAME}" \
              --subscription-tier basic \
              --region "${CLUSTER_REGION}"; then
              echo "‚ùå Error: Failed to create registry"
              exit 1
            fi
            
            echo "ü¶© Configuring registry garbage collection..."
            if ! doctl registry garbage-collection start \
              --include-untagged-manifests \
              --force; then
              echo "‚ö†Ô∏è Warning: Failed to configure garbage collection"
              # Don't exit on garbage collection failure, it's not critical
            fi
            
            echo "‚úÖ Registry created and configured successfully"
          else
            echo "‚úÖ Registry already exists"
          fi
          
          # Verify registry is accessible
          echo "ü¶© Verifying registry access..."
          if ! doctl registry get > /dev/null 2>&1; then
            echo "‚ùå Error: Registry verification failed"
            exit 1
          fi
          
          echo "ü¶© Checking Kubernetes cluster..."
          if ! doctl kubernetes cluster get "${CLUSTER_NAME}" > /dev/null 2>&1; then
            echo "ü¶© Creating Kubernetes cluster: ${CLUSTER_NAME}..."
            if ! doctl kubernetes cluster create "${CLUSTER_NAME}" \
              --region "${CLUSTER_REGION}" \
              --size "${CLUSTER_SIZE}" \
              --count "${CLUSTER_NODE_COUNT}" \
              --tag "${CLUSTER_NAME}" \
              --wait; then
              echo "‚ùå Error: Failed to create cluster ${CLUSTER_NAME}"
              exit 1
            fi
            
            echo "ü¶© Configuring cluster auto-scaling..."
            if ! doctl kubernetes cluster node-pool update "${CLUSTER_NAME}" default \
              --auto-scale \
              --min-nodes 2 \
              --max-nodes 4; then
              echo "‚ö†Ô∏è Warning: Failed to configure auto-scaling"
            fi
            
            echo "‚úÖ Cluster created and configured successfully"
          else
            echo "‚úÖ Cluster ${CLUSTER_NAME} already exists"
          fi
          
          echo "ü¶© Attaching resources to project..."
          
          # Get the Kubernetes cluster ID
          CLUSTER_ID=$(doctl kubernetes cluster get "${CLUSTER_NAME}" --format ID --no-header)
          if [ ! -z "$CLUSTER_ID" ]; then
            CLUSTER_URN="do:kubernetes:${CLUSTER_ID}"
            echo "Found cluster URN: ${CLUSTER_URN}"
          else
            echo "‚ö†Ô∏è Warning: Could not get cluster ID"
          fi
          
          # Get registry ID - note that we need to extract just the ID from the registry info
          REGISTRY_INFO=$(doctl registry get --format ID --no-header)
          if [ ! -z "$REGISTRY_INFO" ]; then
            # The registry ID is the last part of the registry info
            REGISTRY_ID=$(echo "$REGISTRY_INFO" | tr -d '\r')
            REGISTRY_URN="do:registry:${REGISTRY_ID}"
            echo "Found registry URN: ${REGISTRY_URN}"
          else
            echo "‚ö†Ô∏è Warning: Could not get registry ID"
          fi
          
          # Build resources array with error checking
          RESOURCES=()
          
          # Add resources if they exist and are properly formatted
          if [ ! -z "$CLUSTER_URN" ] && [[ "$CLUSTER_URN" =~ ^do:kubernetes:[a-zA-Z0-9-]+$ ]]; then
            RESOURCES+=("${CLUSTER_URN}")
            echo "Adding cluster to resources: ${CLUSTER_URN}"
          else
            echo "‚ö†Ô∏è Warning: Invalid cluster URN format: ${CLUSTER_URN}"
          fi
          
          if [ ! -z "$REGISTRY_URN" ] && [[ "$REGISTRY_URN" =~ ^do:registry:[a-zA-Z0-9-]+$ ]]; then
            RESOURCES+=("${REGISTRY_URN}")
            echo "Adding registry to resources: ${REGISTRY_URN}"
          else
            echo "‚ö†Ô∏è Warning: Invalid registry URN format: ${REGISTRY_URN}"
          fi
          
          # Debug output
          echo "Number of resources to attach: ${#RESOURCES[@]}"
          echo "Resources array contents:"
          printf '%s\n' "${RESOURCES[@]}"
          
          # Only try to attach if we have resources
          if [ ${#RESOURCES[@]} -gt 0 ]; then
            echo "ü¶© Attaching resources to project ${PROJECT_NAME} (ID: ${PROJECT_ID})..."
            
            # Build the resources string with proper quoting
            RESOURCES_STRING=""
            for resource in "${RESOURCES[@]}"; do
              RESOURCES_STRING+="--resource='${resource}' "
            done
            
            echo "Resource string for doctl: ${RESOURCES_STRING}"
            
            # Try to attach resources with full error output
            if ! eval "doctl projects resources assign '${PROJECT_ID}' ${RESOURCES_STRING}"; then
              echo "‚ö†Ô∏è Warning: Failed to attach resources to project"
              echo "ü¶© Current project resources:"
              doctl projects resources list "${PROJECT_ID}" --format "Resource Type,Resource ID" --no-header || true
            else
              echo "‚úÖ Resources attached to project successfully"
              echo "ü¶© Current project resources:"
              doctl projects resources list "${PROJECT_ID}" --format "Resource Type,Resource ID" --no-header || true
            fi
          else
            echo "‚ö†Ô∏è Warning: No valid resources to attach"
          fi
          
          # Verify project resources
          echo "ü¶© Verifying project resources..."
          if ! doctl projects resources list "${PROJECT_ID}" --format "Resource Type,Resource ID" --no-header; then
            echo "‚ö†Ô∏è Warning: Could not verify project resources"
          fi
          
          echo "ü¶© Verifying infrastructure..."
          if ! doctl registry get > /dev/null 2>&1; then
            echo "‚ùå Error: Registry verification failed"
            exit 1
          fi
          
          if ! doctl kubernetes cluster get "${CLUSTER_NAME}" > /dev/null 2>&1; then
            echo "‚ùå Error: Cluster verification failed"
            exit 1
          fi
          
          if ! doctl projects get "${PROJECT_ID}" > /dev/null 2>&1; then
            echo "‚ùå Error: Project verification failed"
            exit 1
          fi
          
          echo "‚úÖ Infrastructure setup completed successfully"

      - name: Configure Docker and Kubernetes üîë
        run: |
          echo "ü¶© Setting up Docker..."
          if ! doctl registry login --expiry-seconds 1800; then
            echo "‚ùå Error: Failed to log in to Docker registry"
            exit 1
          fi
          
          echo "ü¶© Setting up Kubernetes..."
          if ! doctl kubernetes cluster kubeconfig save "$CLUSTER_NAME" --expiry-seconds 1800; then
            echo "‚ùå Error: Failed to save Kubernetes config"
            exit 1
          fi
          
          echo "ü¶© Verifying Kubernetes connection..."
          if ! kubectl cluster-info; then
            echo "‚ùå Error: Failed to connect to Kubernetes cluster"
            exit 1
          fi
          
          echo "ü¶© Creating registry credentials..."
          if ! doctl registry docker-config > docker-config.json; then
            echo "‚ùå Error: Failed to get Docker config"
            exit 1
          fi
          
          DOCKER_CONFIG_BASE64=$(base64 -w 0 docker-config.json)
          echo "DOCKER_CONFIG_BASE64=${DOCKER_CONFIG_BASE64}" >> $GITHUB_ENV
          
          echo "‚úÖ Configuration completed successfully"

      - name: Setup common functions üõ†Ô∏è
        run: |
          # Create shared functions file
          cat << 'EOF' > .github/shared-functions.sh
          # Function to retry Docker operations
          docker_retry() {
            local cmd=$1
            local max_attempts=3
            local attempt=1
            local wait_time=10
            
            while [ $attempt -le $max_attempts ]; do
              echo "ü¶© Attempt $attempt of $max_attempts: $cmd"
              if eval "$cmd" > /dev/null 2>&1; then
                return 0
              else
                echo "‚ùå Attempt $attempt failed"
                if [ $attempt -eq $max_attempts ]; then
                  echo "‚ùå All attempts failed for command: $cmd"
                  return 1
                fi
                echo "ü¶© Waiting ${wait_time}s before retry..."
                sleep $wait_time
                wait_time=$((wait_time * 2))
                attempt=$((attempt + 1))
              fi
            done
          }
          EOF
          
          chmod +x .github/shared-functions.sh
          echo "‚úÖ Common functions setup completed"

      - name: Check for changes üîç
        id: check-changes
        run: |
          # Get the last successful deployment tag
          LAST_VERSION=$(git tag -l "v1.0.*" | sort -V | tail -n 1)
          if [ -z "$LAST_VERSION" ]; then
            echo "No previous version found, building all images"
            echo "backend_changed=true" >> $GITHUB_OUTPUT
            echo "frontend_changed=true" >> $GITHUB_OUTPUT
            exit 0
          fi
          
          echo "ü¶© Comparing changes with last version: ${LAST_VERSION}"
          
          # Check for changes in different components
          BACKEND_CHANGED=$(git diff --quiet $LAST_VERSION HEAD backend/ || echo "true")
          FRONTEND_CHANGED=$(git diff --quiet $LAST_VERSION HEAD frontend/ || echo "true")
          
          # If no changes detected but version is different, something changed
          if [ "$BACKEND_CHANGED" != "true" ] && [ "$FRONTEND_CHANGED" != "true" ]; then
            echo "No direct changes detected, checking if version changed"
            if [ "$LAST_VERSION" != "${VERSION}" ]; then
              echo "Version changed, building all images"
              BACKEND_CHANGED="true"
              FRONTEND_CHANGED="true"
            fi
          fi
          
          # Export the results
          echo "backend_changed=${BACKEND_CHANGED:-false}" >> $GITHUB_OUTPUT
          echo "frontend_changed=${FRONTEND_CHANGED:-false}" >> $GITHUB_OUTPUT
          
          echo "Backend changed: ${BACKEND_CHANGED:-false}"
          echo "Frontend changed: ${FRONTEND_CHANGED:-false}"

      - name: Build and push web service image üèóÔ∏è
        if: steps.check-changes.outputs.backend_changed == 'true'
        run: |
          source .github/shared-functions.sh
          
          echo "ü¶© Building web service image..."
          if ! docker_retry "docker build --quiet --build-arg PROFILE=web-service -t ${REGISTRY}/${REGISTRY_NAME}/web-service:${VERSION} -t ${REGISTRY}/${REGISTRY_NAME}/web-service:latest backend"; then
            echo "‚ùå Failed to build web service image"
            exit 1
          fi
          
          echo "ü¶© Pushing web service images..."
          if ! docker_retry "docker push ${REGISTRY}/${REGISTRY_NAME}/web-service:${VERSION}"; then
            echo "‚ùå Failed to push web service version image"
            exit 1
          fi
          if ! docker_retry "docker push ${REGISTRY}/${REGISTRY_NAME}/web-service:latest"; then
            echo "‚ùå Failed to push web service latest image"
            exit 1
          fi
          echo "‚úÖ Web service image built and pushed"

      - name: Build and push cache updater image üèóÔ∏è
        if: steps.check-changes.outputs.backend_changed == 'true'
        run: |
          source .github/shared-functions.sh
          
          echo "ü¶© Building cache updater image..."
          if ! docker_retry "docker build --quiet --build-arg PROFILE=cache-updater -t ${REGISTRY}/${REGISTRY_NAME}/cache-updater:${VERSION} -t ${REGISTRY}/${REGISTRY_NAME}/cache-updater:latest backend"; then
            echo "‚ùå Failed to build cache updater image"
            exit 1
          fi
          
          echo "ü¶© Pushing cache updater images..."
          if ! docker_retry "docker push ${REGISTRY}/${REGISTRY_NAME}/cache-updater:${VERSION}"; then
            echo "‚ùå Failed to push cache updater version image"
            exit 1
          fi
          if ! docker_retry "docker push ${REGISTRY}/${REGISTRY_NAME}/cache-updater:latest"; then
            echo "‚ùå Failed to push cache updater latest image"
            exit 1
          fi
          echo "‚úÖ Cache updater image built and pushed"

      - name: Build and push frontend image üé® ü¶©
        if: steps.check-changes.outputs.frontend_changed == 'true'
        run: |
          source .github/shared-functions.sh
          
          echo "ü¶© Building frontend image..."
          if ! docker_retry "docker build --quiet -t ${REGISTRY}/${REGISTRY_NAME}/frontend:${VERSION} ./frontend"; then
            echo "‚ùå Failed to build frontend image"
            exit 1
          fi
          
          echo "ü¶© Pushing frontend images..."
          if ! docker_retry "docker push ${REGISTRY}/${REGISTRY_NAME}/frontend:${VERSION}"; then
            echo "‚ùå Failed to push frontend version image"
            exit 1
          fi
          
          echo "ü¶© Tagging and pushing latest frontend..."
          if ! docker_retry "docker tag ${REGISTRY}/${REGISTRY_NAME}/frontend:${VERSION} ${REGISTRY}/${REGISTRY_NAME}/frontend:latest"; then
            echo "‚ùå Failed to tag frontend latest image"
            exit 1
          fi
          if ! docker_retry "docker push ${REGISTRY}/${REGISTRY_NAME}/frontend:latest"; then
            echo "‚ùå Failed to push frontend latest image"
            exit 1
          fi
          
          echo "‚úÖ Frontend image built and pushed"
      - name: Cleanup old images üßπ ü¶©
        run: |
          echo "ü¶© Cleaning up old images..."
          if ! ./.github/scripts/cleanup-registry.sh; then
            echo "‚ö†Ô∏è Warning: Image cleanup had some issues"
          fi
          echo "‚úÖ Image cleanup completed"

      - name: Setup Kubernetes Dependencies üéØ ü¶©
        run: |
          echo "ü¶© Installing Helm..."
          curl -fsSL https://raw.githubusercontent.com/helm/helm/master/scripts/get-helm-3 | bash
          
          echo "ü¶© Adding Helm repositories..."
          helm repo add ingress-nginx https://kubernetes.github.io/ingress-nginx
          helm repo update
          
          echo "ü¶© Setting up SSL certificate..."
          CERT_NAME="${{ env.DOMAIN_NAME }}-cert"
          
          # Check if certificate already exists and is valid  
          echo "ü¶© Checking for existing certificate..."
          EXISTING_CERT_ID=$(doctl compute certificate list --format ID,Name,State --no-header | grep "${CERT_NAME}" | grep "verified" | awk '{print $1}')
          
          if [ -z "$EXISTING_CERT_ID" ]; then
            echo "ü¶© No valid certificate found. Creating new one..."
            if ! doctl compute certificate create \
              --name ${CERT_NAME} \
              --type lets_encrypt \
              --dns-names ${{ env.DOMAIN_NAME }}.${{ env.DOMAIN_SUFFIX }}; then
              echo "‚ùå Error: Failed to create certificate"
              exit 1
            fi
            
            echo "ü¶© Waiting for certificate to be ready..."
            for i in {1..30}; do
              if doctl compute certificate list | grep -q "${CERT_NAME}.*verified"; then
                echo "‚úÖ Certificate is ready"
                break
              fi
              if [ $i -eq 30 ]; then
                echo "‚ùå Error: Certificate creation timed out"
                exit 1
              fi
              echo "ü¶© Waiting for certificate... (attempt $i/30)"
              sleep 10
            done
          else
            echo "‚úÖ Using existing verified certificate with ID: $EXISTING_CERT_ID"
          fi
          
          echo "ü¶© Installing NGINX Ingress Controller..."
          
          # Function to sanitize name for load balancer
          sanitize_name() {
            echo "$1" | tr '[:upper:]' '[:lower:]' | sed 's/[^a-z0-9-]/-/g' | sed 's/--*/-/g' | sed 's/^-//;s/-$//'
          }
          
          # Sanitize the load balancer name
          LB_NAME=$(sanitize_name "${{ env.DOMAIN_NAME }}-lb")
          echo "ü¶© Using sanitized load balancer name: ${LB_NAME}"
          
          # Function to check load balancer status
          check_lb_status() {
            local lb_id=$1
            local status=$(doctl compute load-balancer get $lb_id --format Status --no-header)
            echo $status
          }
          
          # Function to wait for load balancer to be ready
          wait_for_lb() {
            local lb_id=$1
            local timeout=300  # 5 minutes timeout
            local interval=10  # Check every 10 seconds
            local elapsed=0
            
            echo "ü¶© Waiting for load balancer to be ready..."
            while [ $elapsed -lt $timeout ]; do
              local status=$(check_lb_status $lb_id)
              
              if [[ "$status" == "active" ]]; then
                echo "‚úÖ Load balancer is ready"
                return 0
              elif [[ "$status" == "errored" ]]; then
                echo "‚ùå Load balancer is in error state"
                return 1
              fi
              
              echo "ü¶© Load balancer status: $status (waited ${elapsed}s)"
              sleep $interval
              elapsed=$((elapsed + interval))
            done
            
            echo "‚ùå Timeout waiting for load balancer"
            return 1
          }
          
          # Function to cleanup NGINX installation
          cleanup_nginx() {
            echo "ü¶© Cleaning up NGINX installation..."
            
            echo "ü¶© Removing NGINX installation..."
            if ! helm uninstall ingress-nginx -n ingress-nginx --wait --timeout 5m 2>/dev/null; then
              echo "‚ö†Ô∏è No existing NGINX installation found or uninstall failed"
            fi
            
            # Wait for all ingress-nginx pods to be removed
            echo "ü¶© Waiting for NGINX pods cleanup..."
            local timeout=60
            local counter=0
            while kubectl get pods -n ingress-nginx 2>/dev/null | grep -q "ingress-nginx"; do
              counter=$((counter + 1))
              if [ $counter -gt $timeout ]; then
                echo "‚ùå Error: Timeout waiting for NGINX pods cleanup"
                return 1
              fi
              echo "ü¶© Waiting for NGINX pods cleanup... ($counter/$timeout)"
              sleep 2
            done
            
            return 0
          }
          
          # Install NGINX Ingress Controller
          echo "ü¶© Installing NGINX Ingress Controller..."
          
          # Get existing load balancer ID before cleanup
          lb_id=$(doctl compute load-balancer list --format ID,Name --no-header | grep "${LB_NAME}" | awk '{print $1}')
          if [ ! -z "$lb_id" ]; then
            echo "ü¶© Found existing load balancer to reuse (ID: ${lb_id})"
          fi
          
          # Cleanup existing installation
          if ! cleanup_nginx; then
            echo "‚ùå Failed to cleanup NGINX installation"
            exit 1
          fi
          
          echo "ü¶© Installing NGINX Ingress with ${lb_id:+"existing"}${lb_id:-"new"} load balancer"
          
          FULL_DOMAIN_NAME="${{ env.DOMAIN_NAME }}.${{ env.DOMAIN_SUFFIX }}"

          echo "ü¶© Installing NGINX Ingress with existing load balancer configuration"

          if ! helm install ingress-nginx ingress-nginx/ingress-nginx \
            --namespace ingress-nginx \
            --create-namespace \
            --set controller.service.annotations."kubernetes\.digitalocean\.com/load-balancer-id"=${lb_id:-""} \
            --set controller.service.annotations."service\.beta\.kubernetes\.io/do-loadbalancer-hostname"=${FULL_DOMAIN_NAME} \
            --set controller.service.annotations."service\.beta\.kubernetes\.io/do-loadbalancer-name"=${LB_NAME} \
            --set controller.service.annotations."service\.beta\.kubernetes\.io/do-loadbalancer-certificate-id"=${EXISTING_CERT_ID} \
            --set controller.service.annotations."service\.beta\.kubernetes\.io/do-loadbalancer-tls-ports"=443 \
            --set controller.service.annotations."service\.beta\.kubernetes\.io/do-loadbalancer-http-ports"=80 \
            --set controller.service.annotations."service\.beta\.kubernetes\.io/do-loadbalancer-protocol"=http \
            --set controller.service.annotations."service\.beta\.kubernetes\.io/do-loadbalancer-protocol"=https \
            --set controller.service.annotations."service\.beta\.kubernetes\.io/do-loadbalancer-redirect-http-to-https"=true \
            --set controller.service.ports.http=80 \
            --set controller.service.ports.https=443 \
            --set controller.service.targetPorts.http=80 \
            --set controller.service.targetPorts.https=80 \
            --wait \
            --timeout 5m; then
            echo "‚ùå NGINX installation failed"
            kubectl get events -n ingress-nginx --sort-by='.lastTimestamp'
            exit 1
          fi
          
          echo "‚úÖ NGINX Ingress Controller installed successfully"

      - name: Attach load balancer to project
        run: |
          echo "ü¶© Attaching load balancer to project..."
          LB_NAME="${{ env.DOMAIN_NAME }}-lb"
          LB_ID=$(doctl compute load-balancer list --format ID,Name --no-header | grep "${LB_NAME}" | awk '{print $1}')
          if [ ! -z "$LB_ID" ]; then
            LB_URN="do:loadbalancer:${LB_ID}"
            PROJECT_ID=$(doctl projects list --format ID,Name --no-header | grep -i "${{ env.PROJECT_NAME }}" | awk '{print $1}')
            if [ ! -z "$PROJECT_ID" ]; then
              echo "ü¶© Attaching load balancer (${LB_URN}) to project (${PROJECT_ID})..."
              if ! doctl projects resources assign "${PROJECT_ID}" --resource="${LB_URN}"; then
                echo "‚ö†Ô∏è Warning: Failed to attach load balancer to project"
              fi
            else
              echo "‚ö†Ô∏è Warning: Could not find project ID"
            fi
          else
            echo "‚ö†Ô∏è Warning: Could not find load balancer to attach to project"
          fi

          echo "ü¶© Creating namespace if not exists..."
          if ! kubectl create namespace ${REGISTRY_NAME} --dry-run=client -o yaml | kubectl apply -f -; then
            echo "‚ùå Error: Failed to create namespace"
            exit 1
          fi

      - name: Create Kubernetes Secrets ü¶©
        run: |
          echo "ü¶© Creating namespace if not exists..."
          if ! kubectl create namespace ${REGISTRY_NAME} --dry-run=client -o yaml | kubectl apply -f -; then
            echo "‚ùå Error: Failed to create namespace"
            exit 1
          fi
          
          echo "ü¶© Creating registry credentials..."
          if ! kubectl create secret docker-registry registry-credentials \
            --namespace=${REGISTRY_NAME} \
            --docker-server=${REGISTRY} \
            --docker-username=${{ env.DIGITALOCEAN_ACCESS_TOKEN }} \
            --docker-password=${{ env.DIGITALOCEAN_ACCESS_TOKEN }} \
            --dry-run=client -o yaml | kubectl apply -f -; then
            echo "‚ùå Error: Failed to create registry credentials"
            exit 1
          fi
          
          echo "ü¶© Creating application secrets..."
          if ! kubectl create secret generic app-secrets \
            --namespace=${REGISTRY_NAME} \
            --from-literal=github.tokens="${{ env.GH_API_TOKENS }}" \
            --dry-run=client -o yaml | kubectl apply -f -; then
            echo "‚ùå Error: Failed to create application secrets"
            exit 1
          fi
          
          echo "‚úÖ Kubernetes secrets created successfully"

      - name: Deploy Kubernetes Configurations üöÄ ü¶©
        env:
          REGISTRY_URL: ${{ env.REGISTRY }}/${{ env.REGISTRY_NAME }}
          DOMAIN_SUFFIX: ${{ env.DOMAIN_SUFFIX }}
          DOMAIN_NAME: ${{ env.DOMAIN_NAME }}
          ENVIRONMENT: ${{ env.ENVIRONMENT }}
          VERSION: ${{ env.VERSION }}
          NODE_ENV: "production"
          API_TIMEOUT: "30000"
          WEB_SERVICE_PORT: "8080"
          CACHE_UPDATER_PORT: "8081"
          WEB_SERVICE_NAME: "web-service"
          CACHE_UPDATER_NAME: "cache-updater"
          JAVA_MAX_HEAP: ${{ env.JAVA_MAX_HEAP }}
          JAVA_MIN_HEAP: ${{ env.JAVA_MIN_HEAP }}
          BACKEND_REQUEST_MEMORY: ${{ env.BACKEND_REQUEST_MEMORY }}
          BACKEND_REQUEST_CPU: ${{ env.BACKEND_REQUEST_CPU }}
          BACKEND_LIMIT_MEMORY: ${{ env.BACKEND_LIMIT_MEMORY }}
          BACKEND_LIMIT_CPU: ${{ env.BACKEND_LIMIT_CPU }}
          BACKEND_REPLICAS: ${{ env.BACKEND_REPLICAS }}
          REGISTRY: ${{ env.REGISTRY }}
          REGISTRY_NAME: ${{ env.REGISTRY_NAME }}
        run: |
          echo "ü¶© Processing and applying Kubernetes configurations..."
          
          # Create a temporary directory for processed files
          mkdir -p processed_k8s
          
          # Process and apply config first
          echo "ü¶© Processing config.yaml..."
          envsubst < kubernetes/base/config.yaml > processed_k8s/config.yaml
          echo "ü¶© Applying ConfigMaps..."
          if ! kubectl apply -n ${REGISTRY_NAME} -f processed_k8s/config.yaml; then
            echo "‚ùå Error: Failed to apply ConfigMaps"
            exit 1
          fi
          
          # Verify ConfigMaps exist
          echo "ü¶© Verifying ConfigMaps..."
          for config in web-service-config cache-updater-config frontend-config; do
            if ! kubectl get configmap -n ${REGISTRY_NAME} $config >/dev/null 2>&1; then
              echo "‚ùå ConfigMap $config not found"
              exit 1
            fi
          done
          
          # Process and apply Redis first
          echo "ü¶© Processing Redis configuration..."
          envsubst < kubernetes/base/redis.yaml > processed_k8s/redis.yaml
          echo "ü¶© Applying Redis..."
          if ! kubectl apply -n ${REGISTRY_NAME} -f processed_k8s/redis.yaml; then
            echo "‚ùå Error: Failed to apply Redis"
            exit 1
          fi
          
          # Wait for Redis to be ready
          echo "ü¶© Waiting for Redis to be ready..."
          if ! kubectl wait --namespace ${REGISTRY_NAME} \
            --for=condition=ready pod \
            --selector=app=redis \
            --timeout=5m; then
            echo "‚ùå Redis is not ready"
            kubectl get pods -n ${REGISTRY_NAME} -l app=redis
            kubectl describe pods -n ${REGISTRY_NAME} -l app=redis
            exit 1
          fi
          echo "‚úÖ Redis is ready"
          
          # Process backend services
          echo "ü¶© Processing backend services..."
          
          # Web Service
          echo "ü¶© Processing web service..."
          WEB_SERVICE=web-service \
          SERVICE_NAME=web-service \
          SERVER_PORT=${WEB_SERVICE_PORT} \
            envsubst < kubernetes/base/backend-service.yaml > processed_k8s/web-service.yaml
          
          # Cache Updater
          echo "ü¶© Processing cache updater..."
          CACHE_UPDATER=cache-updater \
          SERVICE_NAME=cache-updater \
          SERVER_PORT=${CACHE_UPDATER_PORT} \
            envsubst < kubernetes/base/backend-service.yaml > processed_k8s/cache-updater.yaml
          
          # Apply services
          echo "ü¶© Applying services..."
          for service in web-service cache-updater; do
            echo "ü¶© Applying $service..."
            if ! kubectl apply -n ${REGISTRY_NAME} -f processed_k8s/$service.yaml; then
              echo "‚ùå Error: Failed to apply $service"
              kubectl get pods -n ${REGISTRY_NAME} -l app=$service
              kubectl describe pods -n ${REGISTRY_NAME} -l app=$service
              exit 1
            fi
          done
          
          # Wait for services to be ready
          echo "ü¶© Waiting for services to be ready..."
          for service in web-service cache-updater; do
            echo "ü¶© Waiting for $service..."
            if ! kubectl wait --namespace ${REGISTRY_NAME} \
              --for=condition=ready pod \
              --selector=app=$service \
              --timeout=5m; then
              echo "‚ùå $service is not ready"
              kubectl get pods -n ${REGISTRY_NAME} -l app=$service
              kubectl describe pods -n ${REGISTRY_NAME} -l app=$service
              exit 1
            fi
          done
          
          # Process and apply remaining files
          for file in kubernetes/base/*.yaml; do
            if [[ "$file" != *"backend-service.yaml"* && \
                  "$file" != *"config.yaml"* && \
                  "$file" != *"redis.yaml"* ]]; then
              echo "ü¶© Processing $file..."
              envsubst < "$file" > "processed_k8s/$(basename "$file")"
              
              echo "ü¶© Applying $(basename "$file")..."
              if ! kubectl apply -n ${REGISTRY_NAME} -f "processed_k8s/$(basename "$file")"; then
                echo "‚ùå Error: Failed to apply $(basename "$file")"
                exit 1
              fi
            fi
          done
          
          # Cleanup
          rm -rf processed_k8s
          
          echo "‚úÖ Kubernetes configurations applied successfully"

      - name: Create DNS Record üåç ü¶©
        run: |
          echo "ü¶© Getting LoadBalancer information..."
          
          # Get the load balancer ID
          LB_NAME="${{ env.DOMAIN_NAME }}-lb"
          LB_ID=$(doctl compute load-balancer list --format ID,Name --no-header | grep "${LB_NAME}" | awk '{print $1}')
          
          if [ -z "$LB_ID" ]; then
            echo "‚ùå Error: Could not find load balancer with name ${LB_NAME}"
            echo "ü¶© Available load balancers:"
            doctl compute load-balancer list
            exit 1
          fi
          
          echo "‚úÖ Found load balancer ID: ${LB_ID}"
          
          # Get the load balancer IP
          LB_IP=$(doctl compute load-balancer get ${LB_ID} --format IP --no-header)
          
          if [ -z "$LB_IP" ]; then
            echo "‚ùå Error: Could not get load balancer IP"
            exit 1
          fi
          
          echo "‚úÖ Got load balancer IP: ${LB_IP}"
          
          echo "ü¶© Checking for existing DNS records..."
          
          # First, clean up any stale records for our subdomain
          echo "ü¶© Cleaning up any stale DNS records..."
          RECORDS_TO_CLEAN=$(doctl compute domain records list ${{ env.DOMAIN_SUFFIX }} --format ID,Type,Name --no-header)
          
          # Clean up any A or CNAME records for our subdomain
          echo "$RECORDS_TO_CLEAN" | while read -r record; do
            RECORD_ID=$(echo $record | awk '{print $1}')
            RECORD_TYPE=$(echo $record | awk '{print $2}')
            RECORD_NAME=$(echo $record | awk '{print $3}')
            
            # Only process records for our subdomain
            if [ "$RECORD_NAME" = "${{ env.DOMAIN_NAME }}" ] || [ "$RECORD_NAME" = "@" ]; then
              if [ "$RECORD_TYPE" = "A" ] || [ "$RECORD_TYPE" = "CNAME" ]; then
                echo "ü¶© Removing old record: Type=$RECORD_TYPE, Name=$RECORD_NAME, ID=$RECORD_ID"
                doctl compute domain records delete ${{ env.DOMAIN_SUFFIX }} $RECORD_ID --force || true
              fi
            fi
          done
          
          echo "ü¶© Creating new A record for subdomain..."
          if ! doctl compute domain records create ${{ env.DOMAIN_SUFFIX }} \
            --record-type A \
            --record-name "${{ env.DOMAIN_NAME }}" \
            --record-data "${LB_IP}" \
            --record-ttl 35; then
            echo "‚ùå Error: Failed to create DNS record"
            exit 1
          fi
          
          echo "‚úÖ DNS record created successfully"
          
          echo "ü¶© Verifying DNS configuration..."
          FINAL_RECORDS=$(doctl compute domain records list ${{ env.DOMAIN_SUFFIX }} --format Type,Name,Data --no-header | grep "${{ env.DOMAIN_NAME }}" || true)
          echo "Current DNS records for ${{ env.DOMAIN_NAME }}.${{ env.DOMAIN_SUFFIX }}:"
          echo "$FINAL_RECORDS"

      - name: Verify Deployment üîç ü¶©
        run: |
          echo "ü¶© Checking deployment status..."
          
          echo "ü¶© Pod Status:"
          kubectl -n ${REGISTRY_NAME} get pods -o wide
          
          echo "ü¶© Service Status:"
          kubectl -n ${REGISTRY_NAME} get services
          
          echo "ü¶© Ingress Status:"
          kubectl -n ${REGISTRY_NAME} get ingress
          
          echo "ü¶© Load Balancer Status:"
          kubectl -n ingress-nginx get service ingress-nginx-controller
          
          echo "ü¶© Events:"
          kubectl -n ${REGISTRY_NAME} get events --sort-by='.lastTimestamp'
          
          # Verify all pods are running
          failed_pods=$(kubectl -n ${REGISTRY_NAME} get pods -o jsonpath='{.items[?(@.status.phase!="Running")].metadata.name}')
          if [ ! -z "$failed_pods" ]; then
            echo "‚ùå Error: The following pods are not running:"
            echo "$failed_pods"
            
            for pod in $failed_pods; do
              echo "ü¶© Describing failed pod $pod:"
              kubectl -n ${REGISTRY_NAME} describe pod $pod
              
              echo "ü¶© Logs for failed pod $pod:"
              kubectl -n ${REGISTRY_NAME} logs $pod --all-containers --tail=50 || true
            done
            exit 1
          fi
          
          echo "‚úÖ Deployment verification completed"

      - name: Create GitHub Deployment üì¶ ü¶©
        uses: chrnorm/deployment-action@v2
        with:
          token: ${{ env.GH_PAT }}
          environment: production
          initial-status: success
          environment-url: https://${{ env.DOMAIN_NAME }}.${{ env.DOMAIN_SUFFIX }}

      - name: Set environment variables
        run: |
          echo "DOMAIN_NAME=major-league-github" >> $GITHUB_ENV
          echo "ENVIRONMENT=production" >> $GITHUB_ENV
          echo "BACKEND_REPLICAS=2" >> $GITHUB_ENV
          echo "FRONTEND_REPLICAS=2" >> $GITHUB_ENV
          # Reduced resource requests and limits
          echo "BACKEND_REQUEST_MEMORY=512Mi" >> $GITHUB_ENV
          echo "BACKEND_REQUEST_CPU=200m" >> $GITHUB_ENV
          echo "BACKEND_LIMIT_MEMORY=1Gi" >> $GITHUB_ENV
          echo "BACKEND_LIMIT_CPU=500m" >> $GITHUB_ENV
          echo "FRONTEND_REQUEST_MEMORY=128Mi" >> $GITHUB_ENV
          echo "FRONTEND_REQUEST_CPU=100m" >> $GITHUB_ENV
          echo "FRONTEND_LIMIT_MEMORY=256Mi" >> $GITHUB_ENV
          echo "FRONTEND_LIMIT_CPU=200m" >> $GITHUB_ENV
          echo "JAVA_MAX_HEAP=768m" >> $GITHUB_ENV
          echo "JAVA_MIN_HEAP=512m" >> $GITHUB_ENV


